% This is "sig-alternate.tex" V1.9 April 2009
% This file should be compiled with V2.4 of "sig-alternate.cls" April 2009
%
% This example file demonstrates the use of the 'sig-alternate.cls'
% V2.4 LaTeX2e document class file. It is for those submitting
% articles to ACM Conference Proceedings WHO DO NOT WISH TO
% STRICTLY ADHERE TO THE SIGS (PUBS-BOARD-ENDORSED) STYLE.
% The 'sig-alternate.cls' file will produce a similar-looking,
% albeit, 'tighter' paper resulting in, invariably, fewer pages.
%
% ----------------------------------------------------------------------------------------------------------------
% This .tex file (and associated .cls V2.4) produces:
%       1) The Permission Statement
%       2) The Conference (location) Info information
%       3) The Copyright Line with ACM data
%       4) NO page numbers
%
% as against the acm_proc_article-sp.cls file which
% DOES NOT produce 1) thru' 3) above.
%
% Using 'sig-alternate.cls' you have control, however, from within
% the source .tex file, over both the CopyrightYear
% (defaulted to 200X) and the ACM Copyright Data
% (defaulted to X-XXXXX-XX-X/XX/XX).
% e.g.
% \CopyrightYear{2007} will cause 2007 to appear in the copyright line.
% \crdata{0-12345-67-8/90/12} will cause 0-12345-67-8/90/12 to appear in the copyright line.
%
% ---------------------------------------------------------------------------------------------------------------
% This .tex source is an example which *does* use
% the .bib file (from which the .bbl file % is produced).
% REMEMBER HOWEVER: After having produced the .bbl file,
% and prior to final submission, you *NEED* to 'insert'
% your .bbl file into your source .tex file so as to provide
% ONE 'self-contained' source file.
%
% ================= IF YOU HAVE QUESTIONS =======================
% Questions regarding the SIGS styles, SIGS policies and
% procedures, Conferences etc. should be sent to
% Adrienne Griscti (griscti@acm.org)
%
% Technical questions _only_ to
% Gerald Murray (murray@hq.acm.org)
% ===============================================================
%
% For tracking purposes - this is V1.9 - April 2009

\documentclass{sig-alternate}
  \pdfpagewidth=8.5truein
  \pdfpageheight=11truein

% Remove copyright space
\makeatletter
\def\@copyrightspace{\relax}
\makeatother

% Packages
\usepackage[table,xcdraw]{xcolor}
\usepackage{hyperref}

\begin{document}

\title{Detecting emotion with force sensitive touchscreens}
\subtitle{[...]}


\numberofauthors{1} %  in this sample file, there are a *total*
% of EIGHT authors. SIX appear on the 'first-page' (for formatting
% reasons) and the remaining two appear in the \additionalauthors section.
%
\author{
% You can go ahead and credit any number of authors here,
% e.g. one 'row of three' or two rows (consisting of one row of three
% and a second row of one, two or three).
%{}
% The command \alignauthor (no curly braces needed) should
% precede each author name, affiliation/snail-mail address and
% e-mail address. Additionally, tag each line of
% affiliation/address with \affaddr, and tag the
% e-mail address with \email.
%
% 1st. author
\alignauthor Kevin Blom\\
       \affaddr{University of Amsterdam}\\
       \affaddr{Science Park 904}\\
       \email{xxxxxx@xxxxxx.xx}
}

\maketitle

\begin{abstract}
	
\end{abstract}

\section{Introduction} % (fold)
\label{sec:introduction}
Affective computing as introduced by Picard\cite{Picard1995} in 1995 lays a foundation for computers and technology to incorporate the recognition and expression of emotions. It can provide better performance when assisting humans or enhance the computers ability to make decisions. It does not have the goal of making computers more human-like, but it is more practical in nature; make computers function with intelligence and sensitivity towards its users\cite{Picard1997}. Since, the measuring of emotion has been a subject of research and several different angles have been discovered to approach it. 

\subsection{Physiological detection} % (fold)
\label{sub:physiology}
One angle uses physiological signals of the human body to measure and detect emotion. In a review by Wioleta\cite{Wioleta2013}, eight studies were collected that measure emotion using one or more physiological signals combined. These signals are \textit{EEG, skin conductance, blood volume pulse, temperature, heart rate, blood pressure, respiration, EMG,} and \textit{ECG}.
% subsection physiology (end)

\subsection{Facial detection} % (fold)
\label{sub:facial_detection}
Facial detection of emotion incorporates the measurement of facial muscle movement, voice or speech \cite{Ververidis2004}, and also includes the eye as point of detection, i.e. movement, blinking, and pupil dilation \cite{Soleymani2015}. By connecting facial muscle movement to visual display of emotions, Ekman et al. \cite{Ekman1969} conclude with a basic set of six mutually exclusive emotions that could be recognized. Expanding, De Silva et al. \cite{Silva1997} found that several emotions are expressed by either visual or auditory cues, or both, meaning that some eomtions can be recognized by visual cues alone, auditory cues alone, or need a combination of both to be detected accurately.
% subsection facial_emotion_detection (end)

\subsection{Posture/gestures emotion detection}
Other means of detection emotions involve the tracking and interpretation of posture and gesture. Wallbott et al. \cite{Wallbott1998} concluded in 1998 that there are, in some cases, distinctive patterns of movement and postural behavior that have a strong correlation to emotions. In other cases, they mention that in absence of patterns there are still distinctive features from which emotion could be inferred. Coulson et al. \cite{Coulson2004} researched static body postures and the recognition of emotions from these body postures by participants. It showed that disgust is a tough emotion to recognize but anger and sadness had over 90\% correct detection rates. Furthermore, happiness and surprise were two emotions that were often confused. Another, more applied research is that of Gao et al. \cite{Gao2012}, where the application of gestures on touch screens was successfully linked to emotional states with the use of a game. The emotional states that were tested for are: excited, relaxed, frustrated and bored, and accuracy of detection reached at minimum 69\%. 

\subsection{Research Question}
From the related work can be concluded that most types of detection of emotions are invasive, either requiring constant monitoring with sensors attached to the body or by constant recording of audio and visual data. The touch screen is a technology a lot of people interact with every day, where they deliberately choose to participate in those interactions. Using touch screen presses as indicators for emotional state would be a unintrusive way of detection emotion without the need for constant monitoring. Subsequently, this leads to the following research question:\\

\textit{Can force sensitive touch screen devices be used to tell more about the mood of the user?}\\

Research done on physical keyboards, pressure seems linked to emotion. However, keyboard on a desk and typing with two hands is not fully comparable to typing on a touch screen. Also, emotion detection with touch screens using gestures, but not when tapping, so room for exploration in that area.


\begin{itemize}
	\item Description of background.
	\item Explanation of why research was necessary.
	\item Description of how research will be undertaken.
\end{itemize}


% Summary. Self-reports of emotion are likely to be more valid to the extent that they relate to currently experienced emotions. Even in this case, though, there are concerns that not all individuals are aware of and/or capable of reporting on their momentary emotional states. Finally, Table 1 follows from our review of this literature in suggesting that dimensional frameworks, relative to discrete ones, better capture this measure of emotion. \cite{Mauss2009}

% section Introduction (end)

\section{Methods} % (fold)
\label{sec:methods}
\begin{itemize}
	\item Overview of the research.
	\item Report of who took part and where.
	\item Report of what procedures were used.
	\item Report of what materials were used.
	\item Report of any statistical analysis used.
\end{itemize}

% section methods (end)

\section{Results} % (fold)
\label{sec:results}
\begin{itemize}
	\item Report of findings.
	\item Reference to any diagrams used.
\end{itemize}
% section results (end)

\section{Discussion} % (fold)
\label{sec:discussion}
\begin{itemize}
	\item Summary of main purpose of research.
	\item Review of most important findings.
	\item Evaluation of findings.
	\item Explanation of findings.
	\item Comparison with other researchers findings.
	\item Description of implications and recommendations.
\end{itemize}


% section discussion (end)

% The following two commands are all you need in the
% initial runs of your .tex file to
% produce the bibliography for the citations in your paper.
\bibliographystyle{abbrv}
\bibliography{library,Alternative}  % sigproc.bib is the name of the Bibliography in this case
% You must have a proper ".bib" file
%  and remember to run:
% latex bibtex latex latex
% to resolve all references
%
% ACM needs 'a single self-contained file'!
%
%APPENDICES are optional
%\balancecolumns

\end{document}