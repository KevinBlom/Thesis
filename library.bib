Automatically generated by Mendeley Desktop 1.17.6
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Preferences -> BibTeX in Mendeley Desktop

@misc{Ekman1992,
abstract = {Emotions are viewed as having evolved through their adaptive value in dealing with fundamental life-tasks. Each emotion has unique features: signal, physiology, and antecedent events. Each emotion also has characteristics in common with other emotions: rapid onset, short duration, unbidden occurrence, automatic appraisal, and coherence among responses. These shared and unique characteristics are the product of our evolution, and distinguish emotions from other affective pheonomena.},
archivePrefix = {arXiv},
arxivId = {a},
author = {Ekman, Paul},
booktitle = {Cognition {\&} Emotion},
doi = {10.1080/02699939208411068},
eprint = {a},
file = {:Users/Kevin/stack/Master Thesis/Thesis Design/references/An-Argument-For-Basic-Emotions.pdf:pdf},
isbn = {0269-9931},
issn = {0269-9931},
number = {3},
pages = {169--200},
pmid = {665},
title = {{An argument for basic emotions}},
volume = {6},
year = {1992}
}
@article{Posner2005,
abstract = {The circumplex model of affect proposes that all affective states arise from cognitive interpretations of core neural sensations that are the product of two independent neurophysiological systems. This model stands in contrast to theories of basic emotions, which posit that a discrete and independent neural system subserves every emotion. We propose that basic emotion theories no longer explain adequately the vast number of empirical observations from studies in affective neuroscience, and we suggest that a conceptual shift is needed in the empirical approaches taken to the study of emotion and affective psychopathologies. The circumplex model of affect is more consistent with many recent findings from behavioral, cognitive neuroscience, neuroimaging, and developmental studies of affect. Moreover, the model offers new theoretical and empirical approaches to studying the development of affective disorders as well as the genetic and cognitive underpinnings of affective processing within the central nervous system.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Posner, Jonathan and Russell, James A and Peterson, Bradley S},
doi = {10.1017/S0954579405050340},
eprint = {NIHMS150003},
file = {:Users/Kevin/stack/Master Thesis/Thesis Design/references/div-class-title-the-circumplex-model-of-affect-an-integrative-approach-to-affective-neuroscience-cognitive-development-and-psychopathology-div.pdf:pdf},
isbn = {0954-5794 (Print) 0954-5794 (Linking)},
issn = {0954-5794},
journal = {Development and psychopathology},
number = {3},
pages = {715--34},
pmid = {16262989},
title = {{The circumplex model of affect: an integrative approach to affective neuroscience, cognitive development, and psychopathology.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16262989},
volume = {17},
year = {2005}
}
@article{H.R.LvZ.L.LinW.J.Yin2008,
abstract = {This paper describes a new approach to emotion recognition based on pressure sensor keyboards. The pressure sensor keyboard is a new product that occurs in the market recently, which produces a pressure sequence when keystroke occurs. The analysis of the pressure sequence should be a novel research area. It has been used for identity verification in our previous research. In this paper, we use the pressure sequence for emotion recognition. Three methods (global features of pressure sequences, dynamic time warping and traditional keystroke dynamics) are proposed for the emotion recognition task; then we combined the three methods together using a classifier fusion technique. Several experiments were performed on a database containing 3000 samples (from 50 individuals, including six emotions: neutral, anger, fear, happiness, sadness and surprise) and the best result were achieved utilizing all the method, obtaining an overall accuracy of 93.4{\%}. Our technique of emotion recognition has been used for intelligent game controlling and several other applications.},
author = {{H. R. Lv, Z. L. Lin, W. J. Yin}, J. Dong},
doi = {10.1109/ICME.2008.4607628},
file = {:Users/Kevin/stack/Master Thesis/Thesis Design/references/lv08.pdf:pdf},
isbn = {978-1-4244-2570-9},
journal = {2008 IEEE International Conference on Multimedia and Expo},
pages = {1089--1092},
title = {{Emotion recognition based on pressure sensor keyboards}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4607628},
year = {2008}
}
@article{Coulson2004,
abstract = {ABSTRACT: A total of 176 computer-generated mannequin figures were produced from descriptions of postural expressions of emotion in order to investigate the attri- bution of emotion to static body postures. Each posture was rendered from 3 view- ing angles and presented to participants in a forced-decision task. Concordance rates for attributions of 6 emotions (anger, disgust, fear, happiness, sadness, and surprise) ranged from zero for many disgust postures to over 90 percent for some anger and sadness postures. Anatomical variables and viewing angle were shown to predict participants' responses. Analysis of the confusion matrix suggested a cir- cumplex solution with happiness and surprise sharing a similar position, and few confusions between the other four emotions. The means by which emotions may be attributed to static body postures are discussed, as are avenues for further research.},
author = {Coulson, Mark},
doi = {10.1023/B:JONB.0000023655.25550.be},
file = {:Users/Kevin/stack/Master Thesis/Thesis Design/references/art{\%}3A10.1023{\%}2FB{\%}3AJONB.0000023655.25550.be.pdf:pdf},
isbn = {0191-5886},
issn = {0191-5886},
journal = {Journal of Nonverbal Behavior},
keywords = {and,and communication of emo-,emotion,expression,facial and vocal expression,posture,posture in the expression,relation of research into,s the expression of,since publication of darwin,the emotions in man,the role of body,tion remains the poor},
number = {2},
pages = {117--139},
pmid = {4869},
title = {{Attributing emotion to static body postures: recongition accuracy, confusion and view point dependence}},
volume = {28},
year = {2004}
}
@article{Picard1995,
abstract = {Computers are beginning to acquire the ability to ex- press and recognize affect, and may soon be given the ability to “have emotions.” The essential role of emotion in both human cognition and perception, as demonstrated by recent neurological studies, indi- cates that affective computers should not only pro- vide better performance in assisting humans, but also might enhance computers' abilities to make de- cisions. This paper presents and discusses key issues in “affective computing,” computing that relates to, arises from, or influences emotions. Models are sug- gested for computer recognition of human emotion, and new applications are presented for computer- assisted learning, perceptual information retrieval, arts and entertainment, and human health and inter- action. Affective computing, coupled with new wear- able computers, will also provide the ability to gather new data necessary for advances in emotion and cog- nition theory.},
author = {Picard, Rosalind W.},
doi = {10.1007/BF01238028},
file = {:Users/Kevin/stack/Master Thesis/Thesis Design/references/1995{\_}Affective computing{\_}Picard.pdf:pdf},
isbn = {0262161702},
issn = {09269630},
journal = {MIT press},
number = {321},
pages = {1--16},
pmid = {18487783},
title = {{Affective Computing}},
url = {papers3://publication/uuid/9C02FCAE-FE2E-4D2C-9707-766804777DC9},
year = {1995}
}
@article{Gao2012,
abstract = {The increasing number of people playing games on touch-screen mobile phones raises the question of whether touch behaviors reflect players' emotional states. This prospect would not only be a valuable eval- uation indicator for game designers, but also for real-time personalization of the game experience. Psychol- ogy studies on acted touch behavior show the existence of discriminative affective profiles. In this article, finger-stroke features during gameplay on an iPod were extracted and their discriminative power analyzed. Machine learning algorithms were used to build systems for automatically discriminating between four emo- tional states (Excited, Relaxed, Frustrated, Bored), two levels of arousal and two levels of valence. Accuracy reached between 69{\%} and 77{\%} for the four emotional states, and higher results (∼89{\%}) were obtained for discriminating between two levels of arousal and two levels of valence. We conclude by discussing the factors relevant to the generalization of the results to applications other than games.},
author = {Gao, Yuan and Bianchi-Berthouze, Nadia and Meng, Hongying},
doi = {10.1145/2395131.2395138},
file = {:Users/Kevin/stack/Master Thesis/Thesis Design/references/a31-gao.pdf:pdf},
isbn = {10730516 (ISSN)},
issn = {10730516},
journal = {ACM Transactions on Computer-Human Interaction},
number = {4},
pages = {1--30},
title = {{What Does Touch Tell Us about Emotions in Touchscreen-Based Gameplay?}},
url = {http://dl.acm.org/citation.cfm?doid=2395131.2395138},
volume = {19},
year = {2012}
}
@article{Wallbott1998,
abstract = {The question whether body movements and body postures are indicative of specific emotions is a matter of debate. While some studies have found evidence for specific body movements accompanying specific emotions, others indicate that movement behavior (aside from facial expression) may be only indicative of the quantity (intensity) of emotion, but not of its quality. The study reported here is an attempt to demonstrate that body movements and postures to some degree are specific for certain emotions. A sample of 224 video takes, in which actors and actresses portrayed the emotions of elated joy, happiness, sadness, despair, fear, terror, cold anger, hot anger, disgust, contempt, shame, guilt, pride, and boredom via a scenario approach, was analyzed using coding schemata for the analysis of body movements and postures. Results indicate that some emotion-specific movement and posture characteristics seem to exist, but that for body movements dierences between emotions can be partly explained by the dimension of activation. While encoder (actor) diferences are rather pronounced with respect to specific movement and posture habits, these dierences are largely independent from the emotion-specific dierences found. The results are discussed with respect to emotion- specific discrete expression models in contrast to dimensional models of emotion encoding.},
author = {Wallbott, Harald G.},
doi = {10.1002/(SICI)1099-0992(1998110)28:6<879::AID-EJSP901>3.0.CO;2-W},
file = {:Users/Kevin/stack/Master Thesis/Thesis Design/references/Wallbott, 1998, bodiliy espression of emotion.pdf:pdf},
isbn = {0046-2772},
issn = {0046-2772},
journal = {European Journal of Social Psychology},
number = {6},
pages = {879--896},
title = {{Bodily Expression of Emotion}},
url = {http://doi.wiley.com/10.1002/(SICI)1099-0992(1998110)28:6{\%}3C879::AID-EJSP901{\%}3E3.0.CO;2-W},
volume = {28},
year = {1998}
}
@article{Silva1997,
author = {Silva, Liyanage C D E and Miyasato, I Tsutomu},
doi = {10.1109/SMC.2015.387},
file = {:Users/Kevin/stack/Master Thesis/Thesis Design/references/00647126.pdf:pdf},
isbn = {0780336763},
number = {September},
pages = {9--12},
title = {{Facial Emotion Recognition Using}},
year = {1997}
}
@misc{Ekman1969,
abstract = {Observers in both literate and preliterate cultures chose the predicted emotion for photographs of the face, although agreement was higher in the literate samples. These findings suggest that the pan-cultural element in facial displays of emotion is the association between facial muscular movements and discrete primary emotions, although cultures may still differ in what evokes an emotion, in rules for controlling the display of emotion, and in behavioral consequences.},
author = {Ekman, Paul and Sorenson, E Richard and Friesen, Wallace V},
booktitle = {Science},
doi = {10.1126/science.164.3875.86},
file = {:Users/Kevin/stack/Master Thesis/Thesis Design/references/pan-cultural{\_}elements{\_}in{\_}facial{\_}displays{\_}of{\_}emotions.pdf:pdf},
isbn = {0036-8075 (Print)},
issn = {0036-8075},
number = {3875},
pages = {86--88},
pmid = {5773719},
title = {{Pan-Cultural Elements in Facial Displays of Emotion}},
url = {http://science.sciencemag.org/content/164/3875/86.abstract},
volume = {164},
year = {1969}
}
@article{Mauss2009,
abstract = {A consensual, componential model of emotions conceptualises them as experiential, physiological, and behavioural responses to personally meaningful stimuli. The present review examines this model in terms of whether different types of emotion-evocative stimuli are associated with discrete and invariant patterns of responding in each response system, how such responses are structured, and if such responses converge across different response systems. Across response systems, the bulk of the available evidence favours the idea that measures of emotional responding reflect dimensions rather than discrete states. In addition, experiential, physiological, and behavioural response systems are associated with unique sources of variance, which in turn limits the magnitude of convergence across measures. Accordingly, the authors suggest that there is no "gold standard" measure of emotional responding. Rather, experiential, physiological, and behavioural measures are all relevant to understanding emotion and cannot be assumed to be interchangeable.},
author = {Mauss, Iris B and Robinson, Michael D},
doi = {10.1080/02699930802204677},
file = {:Users/Kevin/Library/Application Support/Mendeley Desktop/Downloaded/Mauss, Robinson - 2009 - Measures of emotion A review.pdf:pdf},
isbn = {1464-0600 (Electronic)$\backslash$r0269-9931 (Linking)},
issn = {1464-0600},
journal = {Cognition and Emotion},
keywords = {Autonomic nervous system,Behaviour,Central nervous system,Emotion,Measurement,Self-report,Specificity,Startle modulation},
number = {2},
pages = {209--237},
pmid = {19809584},
title = {{Measures of emotion: A review.}},
url = {http://www.tandfonline.com/doi/abs/10.1080/02699930802204677},
volume = {23},
year = {2009}
}
@article{Singh2015,
abstract = {In this article, we describe the Differential Equations and Optimization Environment (DOpElib). DOpElib is a software library that provides a unified interface to high level algorithms such as time-stepping methods, nonlinear solvers and optimization routines. This structure ensures that, first of all, the user is only required to write those sections of code that are specific to the considered problem. Second, the exchange of parts of the used routines is possible with only a few lines of code to change instead of large reimplementations. The article illustrates the design principles and various features of DOpElib and provides some numerical results as demonstration for the versatility of the software},
archivePrefix = {arXiv},
arxivId = {arXiv:1502.07526v1},
author = {Singh, Munindar P.},
doi = {10.1145/0000000.0000000},
eprint = {arXiv:1502.07526v1},
file = {:Users/Kevin/Downloads/18a436d92b0bfe3b53ea6fe023649e775376.pdf:pdf},
isbn = {9781577357384},
issn = {10450823},
journal = {IJCAI International Joint Conference on Artificial Intelligence},
number = {March},
pages = {4207--4211},
pmid = {1000285845},
title = {{Norms as a basis for governing sociotechnical systems}},
volume = {2015-Janua},
year = {2015}
}
@article{Shah2015,
abstract = {The role of affect and emotion in interactive system design is an active and recent research area. The aim is to make systems more responsive to user's needs and expectations. The first step towards affective interaction is to recognize user's emotional state. Literature contains many works on emotion recognition. In those works, facial muscle movement, gestures, postures and physiological signals were used for recognition. The methods are computation intensive and require extra hardware (e.g., sensors and wires). In this work, we propose a simpler model to predict the affective state of a touch screen user. The prediction is done based on the user's touch input, namely the finger strokes. We defined seven features based on the strokes. A linear combination of these features is proposed as the predictor, which can predict a user's affective state into one of the three states: positive (happy, excited and elated), negative (sad, anger, fear, disgust) and neutral (calm, relaxed and contented). The model alleviates the need for extra setup as well as extensive computation, making it suitable for implementation on mobile devices with limited resources. The model is developed and validated with empirical data involving 57 participants performing 7 touch input tasks. The validation study demonstrates a high prediction accuracy of 90.47 {\%}. The proposed model and its empirical development and validation are described in this paper.},
author = {Shah, Sachin and Teja, J. Narasimha and Bhattacharya, Samit},
doi = {10.1186/s40166-015-0013-z},
file = {:Users/Kevin/stack/Master Thesis/Thesis Design/references/art{\%}3A10.1186{\%}2Fs40166-015-0013-z.pdf:pdf},
issn = {2194-0827},
journal = {Journal of Interaction Science},
keywords = {emotional state touch screen,linear regression empirical study,strike and tap features},
number = {1},
pages = {6},
publisher = {Journal of Interaction Science},
title = {{Towards affective touch interaction: predicting mobile user emotion from finger strokes}},
url = {http://www.journalofinteractionscience.com/content/3/1/6},
volume = {3},
year = {2015}
}
@article{Wioleta2013,
abstract = {review},
author = {Wioleta, Szwoch},
doi = {10.1109/HSI.2013.6577880},
file = {:Users/Kevin/stack/Master Thesis/Thesis Design/references/06577880.pdf:pdf},
isbn = {9781467356374},
issn = {2158-2246},
journal = {Human System Interaction (HSI), 2013 The 6th {\ldots}},
keywords = {4,affective computing,applications of emotion recognition,emotion recognition,physiological signals,possible,so there are many,their emotions explicitly,using physiological},
pages = {556--561},
title = {{Using physiological signals for emotion recognition}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=6577880},
year = {2013}
}
